#!/usr/bin/env python
"""
DINOv2 Adapter GPU æµ‹è¯•è„šæœ¬
è¿™ä¸ªè„šæœ¬ä¼šåœ¨ GPU ä¸Šå®Œæ•´æµ‹è¯• DINOv2 Adapter çš„åŠŸèƒ½
"""

import sys
import torch

print("=" * 70)
print("  DINOv2 Adapter GPU å®Œæ•´æµ‹è¯•")
print("=" * 70)

# 1. æ£€æŸ¥ CUDA
print("\n[1] æ£€æŸ¥ CUDA ç¯å¢ƒ...")
if not torch.cuda.is_available():
    print("âŒ CUDA ä¸å¯ç”¨ï¼MSDeformAttn ä»…æ”¯æŒ GPUã€‚")
    print("   è¯·ç¡®ä¿ï¼š")
    print("   1. å·²å®‰è£… CUDA ç‰ˆæœ¬çš„ PyTorch")
    print("   2. è®¾ç½®äº†æ­£ç¡®çš„ CUDA_VISIBLE_DEVICES")
    print("   3. GPU é©±åŠ¨æ­£å¸¸")
    sys.exit(1)

device = torch.device("cuda")
print(f"âœ… CUDA å¯ç”¨")
print(f"   GPU: {torch.cuda.get_device_name(0)}")
print(f"   CUDA ç‰ˆæœ¬: {torch.version.cuda}")
print(f"   PyTorch ç‰ˆæœ¬: {torch.__version__}")

# 2. æ£€æŸ¥ MultiScaleDeformableAttention CUDA æ‰©å±•
print("\n[2] æ£€æŸ¥ CUDA æ‰©å±•...")
try:
    import MultiScaleDeformableAttention as MSDA
    print("âœ… MultiScaleDeformableAttention CUDA æ‰©å±•åŠ è½½æˆåŠŸ")
except ImportError as e:
    print(f"âŒ CUDA æ‰©å±•åŠ è½½å¤±è´¥: {e}")
    print("   è¯·è¿è¡Œ: cd models/backbones/nets/ops && python setup.py build_ext --inplace")
    sys.exit(1)

# 3. å¯¼å…¥ DinoAdapter
print("\n[3] å¯¼å…¥ DinoAdapter...")
try:
    from models.backbones import DinoAdapter
    print("âœ… DinoAdapter å¯¼å…¥æˆåŠŸ")
except Exception as e:
    print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 4. åˆ›å»ºæ¨¡å‹å¹¶ç§»åŠ¨åˆ° GPU
print("\n[4] åˆ›å»º DinoAdapter å¹¶ç§»åŠ¨åˆ° GPU...")
try:
    adapter = DinoAdapter(
        num_heads=6,  # ViT-Small
        embed_dim=384,
        depth=12,
        pretrained_vit=False,  # è·³è¿‡æƒé‡åŠ è½½
        freeze_dino=False,
        patch_size=14
    )
    adapter = adapter.to(device)
    adapter.eval()
    print("âœ… DinoAdapter åˆ›å»ºæˆåŠŸå¹¶å·²ç§»åŠ¨åˆ° GPU")
    print(f"   embed_dim: {adapter.embed_dim}")
    print(f"   num_heads: {adapter.num_heads}")
    print(f"   patch_size: {adapter.patch_size}")
except Exception as e:
    print(f"âŒ åˆ›å»ºå¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 5. æµ‹è¯•å‰å‘ä¼ æ’­
print("\n[5] æµ‹è¯•å‰å‘ä¼ æ’­ (256x704)...")
try:
    h, w = 256, 704
    batch_size = 2
    
    # åˆ›å»ºè¾“å…¥å¼ é‡ï¼ˆç¡®ä¿åœ¨ GPU ä¸Šï¼‰
    img = torch.randn(batch_size, 3, h, w, device=device, dtype=torch.float32)
    print(f"   è¾“å…¥å¼ é‡: shape={img.shape}, device={img.device}")
    
    with torch.no_grad():
        features, x_out = adapter(img)
    
    print("âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼")
    print(f"   è¾“å‡ºç‰¹å¾æ•°é‡: {len(features)}")
    for i, f in enumerate(features):
        print(f"   f{i+1}: {f.shape}, device={f.device}")
    print(f"   x_out: {x_out.shape}, device={x_out.device}")
    
except Exception as e:
    print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
    import traceback
    traceback.print_exc()
    sys.exit(1)

# 6. æµ‹è¯•å¤šç§å°ºå¯¸
print("\n[6] æµ‹è¯•å¤šç§å›¾åƒå°ºå¯¸...")
test_sizes = [
    (224, 224),
    (256, 704),
    (480, 640),
    (300, 500),
]

all_passed = True
for h, w in test_sizes:
    try:
        img = torch.randn(1, 3, h, w, device=device)
        with torch.no_grad():
            features, x_out = adapter(img)
        print(f"   âœ… {h}x{w}: æˆåŠŸ (f1={features[0].shape[2:]})")
    except Exception as e:
        print(f"   âŒ {h}x{w}: å¤±è´¥ - {e}")
        all_passed = False

# 7. æ€»ç»“
print("\n" + "=" * 70)
if all_passed:
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼DINOv2 Adapter å·¥ä½œæ­£å¸¸ã€‚")
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("  1. è¿è¡Œå®Œæ•´æ£€æŸ¥: python tools/check_dinov2_integration.py")
    print("  2. å¼€å§‹è®­ç»ƒ: bash tools/dist_train.sh configs/racformer_r50_nuimg_704x256_f8_with_dinov2_fixed.py 2")
else:
    print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ä¸Šè¿°é”™è¯¯ã€‚")
print("=" * 70)

